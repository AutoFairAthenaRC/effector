\documentclass[twoside]{article}

\usepackage{aistats2023}
% If your paper is accepted, change the options for the package
% aistats2023 as follows:
%
%\usepackage[accepted]{aistats2023}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}
\bibliographystyle{plainnat}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\newcommand{\dfdx}{\frac{\partial f}{\partial x_s}}
\newcommand{\xc}{\mathbf{x_c}}
\newcommand{\DY}{\mathbf{\Delta Y}}
\newcommand{\xb}{\mathbf{x}}
\newcommand{\Xcb}{\mathbf{X}_c}
\newcommand{\Xb}{\mathcal{X}}

\begin{document}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Instructions for Paper Submissions to AISTATS 2023}

\aistatsauthor{ Author 1 \And Author 2 \And  Author 3 }

\aistatsaddress{ Institution 1 \And  Institution 2 \And Institution 3 } ]

\begin{abstract}
  The Abstract paragraph should be indented 0.25 inch (1.5 picas) on
  both left and right-hand margins. Use 10~point type, with a vertical
  spacing of 11~points. The \textbf{Abstract} heading must be centered,
  bold, and in point size 12. Two line spaces precede the
  Abstract. The Abstract must be limited to one paragraph.
\end{abstract}


\section{INTRODUCTION}

Recently, ML has flourished in critical domains, such as healthcare
and finance. In these areas, we need ML models that not only predict
accurately but also explain their predictions. Therefore, Explainable
AI (XAI), the field that provides interpretations for the prediction
mechanism of complex black-box models, has increased interest. XAI
literature distinguishes between local and global interpretation
methods~\citep{Molnar2020interpretable}. Local methods explain a
specific prediction, whereas global methods explain the entire model
behavior. Global methods provide a universal explanation, summarizing
the numerous local explanations into a single interpretable outcome,
usually a number or a plot. If a user wants to know which features are
significant (feature importance) or whether a particular feature has a
positive or negative effect on the output (feature effect), they
should opt for a global explainability technique. Aggregating the
individual explanations for producing a concise global one comes at a
cost. Under strong feature interactions, the global explanation may
obfuscate heterogeneous effects~\citep{Herbinger2022repid} that exist
under the hood; a phenomenon called aggregation
bias~\citep{mehrabi2021survey}.

Feature effect\citep{Gromping2020MAEP} forms a fundamental category of
global explainability methods, isolating a single feature's average
impact on the output. Feature effect methods suffer from aggregation
bias because the rationale behind the average effect might be
unclear. For example, a feature with zero average effect may indicate
that the feature has no effect on the output or, contrarily, it has a
highly positive effect in some cases and a highly negative in
others. There are three widely-used feature effect methods; Partial
Dependence Plots (PDP)\citep{friedman2001greedy}, Marignal Plots
(MP)\citep{apley2020visualizing} and Aggregated Local Effects
(ALE)\citep{apley2020visualizing}. PDP and MP have been criticized for
computing erroneous effects when the input features are (highly)
correlated, which is the case in most ML setups. Therefore, ALE has
been established as the state-of-the-art feature effect method.

However, ALE faces two crucial drawbacks. First, it does not provide a
way to inform the user about potential heterogeneous effects that are
hidden behind the average effect. In contrast, in the case of PDP, the
heterogeneous effects can be spotted by exploring the Individual
Conditional Expectations (ICE)\citep{goldstein2015peeking}. Second,
ALE requires an additional step, where the axis of the feature of
interest is split in \(K\) fixed-size non-overlapping intervals, where
\(K\) is a hyperparameter provided by the user. So far, this splitting
is done in a blind way, i.e., the user does not have an indication
about the parameter K, which often leads to inconsistent explanations.

In this paper, we extend ALE with a probabilistic component for
measuring the uncertainty of the global explanation. The uncertainty
of the global explanation expresses how certain we are that the global
(expected) explanation is valid if applied to an instance drawn at
random and informs the user about the level of heterogeneous effects
behind the expected explanation. The probabilistic extension completes
ALE, as ICE plots complement PDP, for revealing the heterogeneous
effects. Our method also transforms the axis-splitting step into an
unsupervised clustering problem, i.e., we search for the optimal
splitting given the instances of the training set. We, therefore,
relieve the user from the obligation of defining a parameter \(K\) by
providing an automated method for finding the optimal bin splitting to
robustly estimate (a) the global (expected) effect and (b) the
uncertainty of the explanation, from the limited samples of the
training set.

\paragraph{Contributions.} The contributions of this paper are the following:

\begin{itemize}
\item We introduce Uncertainty DALE (UDALE), an extension of DALE that
  quantifies the uncertainty of the global explanation, i.e.~the level
  of heterogeneous effects hidden behind the global explanation.
\item We provide an algorithm that automatically computes the optimal
  axis-splitting for robustly estimating the the global effect and the
  uncertainty.
\item We formally prove that our method finds the optimal grouping of
  samples, minimizing the added uncertainty over the unavoidable
  heterogeneity that is the lower-bound of the objective.
\item We provide empirical evaluation of the method in artificial and
  real datasets.
\end{itemize}

The implementation of our method and the code for reproducing all the
experiments is provided in the submission and will become publicly
available upon acceptance.


\section{BACKGROUND AND RELATED WORK}

\paragraph{Notation.} We refer to random variables (rv) using
uppercase \( X \), whereas to simple variables with plain lowercase
\( x \). Bold denotes a vector; \( \xb \) for simple variables or
\(\mathbf{X}\) for rvs. Often, we partition the input vector
\(\xb \in \mathbb{R}^D\) to the feature of interest
\(x_s \in \mathbb{R} \) and the rest of the features
\(\xc \in \mathbb{R}^{D-1}\). For convenience we denote it as
\((x_s, \mathbf{x}_c)\), but we clarify that it corresponds to the
vector \((x_1, \cdots , x_s, \cdots, x_D)\). Equivalently, we denote
the corresponding rv as \(X = (X_s, \mathbf{X}_c)\). The black-box
function is \(f : \mathbb{R}^D \rightarrow \mathbb{R}\) and the
feature effect of the \(s\)-th feature is
\(f^{\mathtt{<method>}}(x_s)\), where \(\mathtt{<method>}\) is the
name of the feature effect method.\footnote{An extensive list of all
  symbols used in the paper is provided in the helping material.}

\paragraph{Feature Effect Methods.} As stated at the Introduction, the
three well-known feature effect methods are: PDPs, MPs and ALE. PDPs
formulate the feature effect of the \(s\)-th attribute as an
expectation over the marginal distribution \(\mathbf{X}_c\), i.e.,
\(f^{\mathtt{PDP}}(x_s) =
\mathbb{E}_{\mathbf{X}_c}[f(x_s,\mathbf{X}_c)]\). MPs formulate it as
an expectation over the conditional \(\mathbf{X}_c|X_s\), i.e.,
\(f^{\mathtt{MP}}(x_s) = \mathbb{E}_{\mathbf{X}_c|X_s = x_s}[f(x_s,
\mathbf{X}_c)]\). ALE computes the global effect at \(x_s\) as the
accumulation of the averaged local effects, which are defined as the
change on the output, i.e.
\( \frac{\partial f(x_s, \mathbf{X}_c)}{\partial x_s} \):

\begin{equation}
  \label{eq:ALE_accumulated_mean}
  f^{\mathtt{ALE}}(x_s) = \int_{z_{s,min}}^{x_s} \mathbb{E}_{\Xcb|X_s=z}\left[\frac{\partial f(z, \Xcb)}{\partial z}\right] \partial z
\end{equation}
%
ALE has specific advantages which gain particular value in cases of
corelated input features. In these cases, PDPs integrate over
unrealistic instances, due to the use of the marginal distribution
\( p(\mathbf{X}_c) \), and MPlots compute aggregated effects, i.e.,
impute the combined effect of sets of features to a single
feature. ALE manages to resolve both issues, and is therefore the only
trustable method in cases of correlated features.

\paragraph{Quantify the Heterogeneous Effects.}

Feature effect methods answer the question \textit{what happens
  (effect) to the output, if I increase/decrease the value of a
  specific feature}. Having answered the question above, it comes
naturally to also wonder \textit{how certain we are about the change
  on the output}. For this reason, a lot of interest is given lately
for quantifying the level of uncertainty, along with the expected
effect. The level of uncertainty is mostly quantified by measuring the
existence of heterogeneous effects, i.e. whether there are local
explanations that deviate from the expected global effect. ICE and
d-ICE plots provide a visual understanding of the heterogeneous
effects on top of PDPs. Another approach targets on grouping the
heterogeneous effects, e.g., allocating ICE plots in homogeneous
clusters, by dividing the input space. Some other approaches, like
H-Statistic, Greenwel, move a step behind and try to quantify the
level of interaction between the input features, a possible cause of
heterogeneous effects. In this case, the interpretation is indirect,
since a strong interaction index is only an indicator of heterogeneous
effects. The aforementioned approaches face two pathogenies; They
either do not quantify the uncertainty of the feature effect directly
or they are based on PDPs, and, therefore, they are subject to the
failure modes of PDPs in cases of correlated features. To the best of
our knowledge, no method so far targets on quantify the uncertainty of
the feature effect as it is modelled by ALE.

\paragraph{Cluster Instances with homogeneous effects.}

In real ML scenarios, the expected feature effect and the uncertainty
are estimated from the limited instances of the training set. ALE
approximation requires an additional step, where the axis of the
\(s\)-th feature is split into a sequence of non-overlaping bins and a
single effect (expectation and uncertainty) is computed from the
population of instances that lie inside each
bin. \citep{apley2020visualizing} proposed estimating the local
effects in each bin by evaluating the black box-funtion at the bin
limits:

\begin{equation}
  \label{eq:ALE_accumulated_mean_est}
  \hat{f}^{\mathtt{ALE}}(x_s) = \sum_{k=1}^{k_x} \frac{1}{|\mathcal{S}_k|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}_k} \left [ f(z_{k}, \xc^i) - f(z_{k-1}, \xc^i)) \right ]
\end{equation}

We denote as \(k_x\) the index of the bin that \(x_s\) belongs to,
i.e. \(k_x: z_{k_x-1} \leq x_s < z_{k_x} \) and \(\mathcal{S}_k\) is
the set of training instance that lie in the \(k\)-th bin, i.e.
\( \mathcal{S}_k = \{ \xb^i : z_{k-1} \leq x^i_s < z_{k} \} \). In
contrast, (cite) proposed the Differential ALE (DALE) estimation for
quantifying the local effects on the training-set instances, instead
of the bin limits:

\begin{equation}
  \label{eq:DALE_accumulated_mean_est}
  \hat{f}^{\mathtt{DALE}}(x_s) = \Delta x \sum_{k=1}^{k_x} \frac{1}{|\mathcal{S}_k|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}_k} \frac{\partial f}{\partial x_s}(\mathbf{x}^i)
\end{equation}
%
Their method has the advantages of remaining on-distribution even when
bins become wider and, most importantly, it allows the recomputation
of the accumulated effect with different bin-splitting in near-zero
computational overhead. However, none of the approximations above
deals with the crucial problem of the optimal bin-spliting. They
partition the axis in \(K\) equally-sized bins without considering the
properties of the underlying data, which can lead to erroneous
approximations.

Instead, we propose treating the axis-spliting step as an unsupervised
clustering problem. The objective of the clustering problem should
fulfill in the best way to contradictory ojectives. First, secure
robust estimations of the expected effect and the uncertainty inside
each bin given the limited instances of the training set and, second,
create bins with as homogeneous local effects as possible, for not
losing fine-grain resolution feature effects due to wide bins.

\section{THE NAME METHOD}
\label{sec:NAME-method}

The NAME method extends the traditional ALE method with a component
for uncertainty quantification and improves the ALE estimation by
automatically discovering the optimal bin-splitting. In
Section~\ref{sec:NAME-definition} we define the component for the
uncertainty quantification. In
Section~\ref{sec:interval-based-estimation}, we show how to estimate
NAME from the limited samples of the training set and we make an
important proof about the aggregated variance defined over a bin. In
Section~\ref{sec:interval-spliting}, we define and solve the problem
of optimal bin-splitting. Finally, in Section~\ref{sec:visualization},
we illustrate the appropriate visualization of NAME for facilitating
its interpretation by a non-expert and we discuss important aspects of
the method

\subsection{Uncertainty Quantification}
\label{sec:NAME-definition}

ALE defines the local effect of the \(s\)-th feature on \(f(\cdot)\)
at point \((x_s, \xc)\) as \(\dfdx (x_s, \xc)\). All the local
explanations at \(x_s\) are, then, weigthed by the conditional
distribution \(p(\xc|x_s)\) and are averaged, to produce the
summarized effect at \(x_s\):

\begin{equation}
  \label{eq:ALE_mean}
  \mu(x_s) = \mathbb{E}_{\Xcb|x_s}\left [\dfdx (x_s, \Xcb)\right ]
\end{equation}
%
The feature effect at \(x_s\) is the accumulation of the averaged
local effects from \(x_{s, min}\) until \(x_s\), i.e.
\(f^{\mathtt{ALE}}(x_s) = \int_{x_{s, min}}^{x_s} \mu(z) \partial z
\). As described at the Introduction, limiting the explanation to the
exepected value level does not shed light to possible heterogeneous
effects behind the averaged explanation. Therefore, we model the
uncertainty of the local effects at \(\mathcal{H}(x_s)\) as the
variance of the local explanations:

\begin{equation}
  \label{eq:ALE_var}
  \mathcal{H}(x_s) := \sigma^2(x_s) = \mathrm{Var}_{\Xcb|x_s}\left [\dfdx (x_s, \Xcb) \right ]
\end{equation}
\noindent
The uncertainty of the explanation emerges from the natural
characteristics of the experiment, i.e.,~the data generating
distribution and the properties of the black-box function. In
Section~\ref{sec:visualization}, we propose appropriate visualizations
for easier interpretation of Eq.~(\ref{eq:ALE_var}). In ALE, the
feature effect at \(x_s\) is the accumulation of the averaged local
effects from \(x_{min}\) until \(x_s\), as shown in
Eq.~(\ref{eq:ALE_accumulated_mean}). Equivalently, we define the
accumulated uncertainty (variance) until \(x_s\), as the integral of
the variances of the local effects:

\begin{equation}
  \label{eq:ALE_accumulated_var}
  f^{\mathtt{ALE}}_{\sigma^2}(x_s) = \int_{z_{s, min}}^{x_s} \sigma^2(z) \partial z
\end{equation}
\noindent

The accumulated uncertainty is not a directly interpretable
quantity. It only helps us define a sensible objective for the
interval spliting step, as we discuss in
Section~\ref{sec:interval-spliting}.

\subsection{Interval-Based Estimation}
\label{sec:interval-based-estimation}

In real scenarios, we have ignorance about the data-generating
distribution \(p(x_s, \mathbf{x}_c)\), so, the estimations are based
on the limited instances of the training set. Estimating
Eqs.~\eqref{eq:ALE_mean},~\eqref{eq:ALE_var} at the granularity of a
point is impossible, because the probability of observing a sample
inside the interval \([x_s - h, x_s + h]\) tends to zero, when
\(h \to 0\). We are, therefore, obliged to split the axis of \(x_s\)
into a sequence of non-overlaping intervals (bins) and estimate the
mean and the variance from the samples that lie inside each bin. The
mean effect at an interval \([z_1, z_2)\) is defined as the mean of
the expected effects:

\begin{equation}
  \label{eq:mu_bin}
  \mu(z_1, z_2) = \frac{1}{z_2 - z_1} \int_{z_1}^{z_2}
  \mathbb{E}_{\xc|x_s=z}\left [\frac{\partial f}{\partial x_s} \right ] \partial z
\end{equation}

\noindent
Similarly, the accumulated variance at an interval \([z_1, z_2)\) is
defined as:

\begin{equation}
  \label{eq:var_bin}
  \sigma^2(z_1, z_2) = \int_{z_1}^{z_2}
  \mathbb{E}_{\xc|x_s=z} \left [ (\frac{\partial
      f}{\partial x_s} - \mu(z_1, z_2) )^2 \right] \partial z
\end{equation}
\paragraph{Theorem 1.} If we define the residual \(\rho(z)\) as the
difference between the expected effect at \(x_s\) and the mean
expected effect at the interval, i.e
\(\rho(z) = \mu(z) - \mu(z_1, z_2)\), then, the accumulated variance
at an interval \([z_1, z_2)\) is the accumulation of the all variances
plus the accumulation of squared residuals inside the interval:

\begin{equation}
 \sigma^2(z_1, z_2) = \int_{z_1}^{z_2} \sigma^2(z) + \rho^2(z) \partial z
\end{equation}
%
The proof is in the Appendix. Theorem 1 decouples the accumulated
variance at an interval into two terms. The first term
\(\int_{z_1}^{z_2} \sigma^2(z) \partial z\), quantifies the aggregated
uncertainty due to the natural characteristics of the experiment
\(\mathcal{H}\) and the second term adds extra nuisance uncertainty
due to the limited resolution \(\mathcal{H}_n\). In other words,
enforcing the computation of a single effect for all points in
\([z_1, z_2)]\), burdens the estimation inside the interval with a
nuisance uncertainty of:

\begin{equation}
  \label{eq:uncertainty_bin}
  \mathcal{H}_{bin}(z_1, z_2) = \int_{z_1}^{z_2} \mathcal{H}(z) + \mathcal{H}_n(z) \partial z
\end{equation}


Eqs.~\eqref{eq:mu_bin},~\eqref{eq:var_bin} can be directly estimated
from the set \(\mathcal{S}\) of the dataset instances with the
\(s\)-th feature lying inside the interval, i.e.,
\( \mathcal{S}= \{ \mathbf{x}^i : z_1 \leq x^i_s < z_2 \} \). The mean
effect at the interval, Eq.~(\ref{eq:mu_bin}) is approximated by:

\begin{equation}
  \label{eq:mean_estimation}
  \hat{\mu}(z_1, z_2) = \frac{1}{|\mathcal{S}|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}} \left [ \dfdx(\mathbf{x}^i) \right ]
\end{equation}

and the accumulated variance, Eq.~(\ref{eq:var_bin}) can be
approximated by

\begin{equation}
  \label{eq:variance_estimation}
  \hat{\sigma}^2(z_1, z_2) = \frac{z_2 - z_1}{|\mathcal{S}|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}} \left ( \dfdx(\mathbf{x}^i) - \hat{\mu}(z_1, z_2) \right )^2
\end{equation}


The approximation is unbiased only if the points are uniformly
distributed in \([z_1, z_2]\). Elaborate.

\subsection{Interval Spliting As A Clustering Problem}
\label{sec:interval-spliting}

We formulate the axis-splitting as an unsupervised clustering
problem. We search for the optimal bin splitting, i.e., the number and
size of consecutive non-overlapping intervals that minimizes the
accumulated variance. The optimization problem is defined as follows:

\begin{equation}
  \label{eq:opt}
\begin{aligned}
\min_{ \{z_0, \ldots, z_K\}} \quad & \mathcal{L} = \sum_{k=1}^K \hat{\sigma}^2(z_{k-1}, z_k) \\
\textrm{s.t.} \quad & |\mathcal{S}_k| \geq N\\
\end{aligned}
\end{equation}

The objective of the optimization problem is the sum of the
accumulated variances in each bin, estimated by the instances of the
training set. As we prove in Theorem 1,
\(\mathcal{L} = \sum_{k=1}^K \mathcal{H}_{bin}(z_{k-1}, z_k)\) is the
sum of the uncertainty of the local explanations \(\mathcal{H}\) due
to heterogeneous effects and the added nuisance uncertainty due to
bin-splitting \(\mathcal{H}_n\). Given that \(\mathcal{H}\) is not
affected by interval splitting, optimizing \(\mathcal{L}\) equals to
finding the sequence of non-overlaping bins that add the minimum
nuisance uncertainty. The restriction of (\ref{eq:opt}) secures that
each bin is populated with enough samples for a robust estimation,
which is set by the parameter \(N\). In other words, the user makes
the following proposal; \textit{find the bin sequence that adds the
  minimum nuisance uncertainty, given that I want at least \(N\)
  points per bin}.

\subsubsection{Algorithm For Solving The Clustering Problem}
\label{sec:dynamic-programing}

Solving the problem of finding (a) the optimal number of bins \(K\)
and (b) the optimal bin limits for each bin
\([z_{k-1}, z_k] \forall k\) to minimize:

\begin{equation}
  \label{eq:1}
  \mathcal{L} = \sum_{k=0}^K \hat{\sigma}_k(z_{k-1}, z_k)
\end{equation}
%
The constraints are that all bins must include more than \(\tau\)
points, i.e., \(|\mathcal{S}_k| \geq \tau\).

\noindent
TODOS. Show theoretically that \(\mathcal{L} \geq \int_{x_{s, \min}}^{x_{s, \max}}\sigma^2(x_s) \partial x_s\)


% Furthermore, we automate the step of splitting the axis into non-overlapping intervals. The need for non-overlapping bins emerges from the ignorance of the data-generating distribution, enforcing all estimations to be based on the limited instances of the training set. Therefore, there is an implicit trade-off behind the formation of bins. Each bin must include enough instances for a robust estimation of the bin feature effect (expected value), and the uncertainty of the explanation (variance). On the other hand, each bin should include points with similar local effects. Therefore, we transform the bin splitting step into an unsupervised clustering problem, encoding the trade-off mentioned above in the objective function. We formally show that the objective of the clustering problem has lower-bound the (unavoidable) heterogeneity, i.e., the aggregated uncertainty of the global explanation. Therefore, we aim to find the optimal grouping of samples that adds the slightest uncertainty over the unavoidable heterogeneity. We finally solve the minimization problem by finding the global optimum using dynamic programming. Our method works out of the box without requiring any input by the user. We provide a theoretical and empirical evaluation of our method.


\subsection{Visualization of NAME Method and Discussion}
\label{sec:visualization}

\begin{itemize}
\item Discuss about the meaning of ALE, to find intervals with some effect
\end{itemize}

\section{SYNTHETIC EXAMPLES}

\section{REAL-WORLD EXAMPLES}


\subsubsection*{Acknowledgements}
All acknowledgments go at the end of the paper, including thanks to reviewers who gave useful comments, to colleagues who contributed to the ideas, and to funding agencies and corporate sponsors that provided financial support. 
To preserve the anonymity, please include acknowledgments \emph{only} in the camera-ready papers.

\bibliography{biblio}

\end{document}
