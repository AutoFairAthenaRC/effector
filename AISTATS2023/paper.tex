\documentclass[twoside]{article}

\usepackage{aistats2023}
% If your paper is accepted, change the options for the package
% aistats2023 as follows:
%
%\usepackage[accepted]{aistats2023}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}
\bibliographystyle{plainnat}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}

\newcommand{\dfdx}{\frac{\partial f}{\partial x_s}}
\newcommand{\xc}{\mathbf{x_c}}
\newcommand{\DY}{\mathbf{\Delta Y}}
\newcommand{\xb}{\mathbf{x}}
\newcommand{\Xcb}{\mathbf{X}_c}
\newcommand{\Xb}{\mathcal{X}}

\begin{document}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Instructions for Paper Submissions to AISTATS 2023}

\aistatsauthor{ Author 1 \And Author 2 \And  Author 3 }

\aistatsaddress{ Institution 1 \And  Institution 2 \And Institution 3 } ]

\begin{abstract}
  The Abstract paragraph should be indented 0.25 inch (1.5 picas) on
  both left and right-hand margins. Use 10~point type, with a vertical
  spacing of 11~points. The \textbf{Abstract} heading must be centered,
  bold, and in point size 12. Two line spaces precede the
  Abstract. The Abstract must be limited to one paragraph.
\end{abstract}


\section{INTRODUCTION}

Recently, ML has flourished in critical domains, such as healthcare
and finance. In these areas, we need ML system with the capability to
explain their predictions, apart from predicting with accuracy. For
this reason there is an increased interest in Explainable AI (XAI),
the field that provides interpretations about the behavior of complex
black-box models. XAI literature distinguishes between local and
global explainability
techniques~\citep{Molnar2020interpretable}. Local methods explain a
specific prediction, whereas global methods explain the entire model
behavior. Global methods provide a universal explanation, summarizing
the numerous local ones into a single interpretable outcome, usually a
number or a plot. If a user wants to get a rough overview about which
features are significant (feature importance) or whether a particular
feature has a positive or negative effect on the output (feature
effect), they should opt for a global explainability technique. On
ther other hand, aggregating the individual explanations for producing
a concise global one is vulnerable to misinterpretations; Under strong
feature interactions, the global explanation may obfuscate
heterogeneous effects~\citep{Herbinger2022repid} that exist under the
hood; a phenomenon called aggregation bias~\citep{mehrabi2021survey}.

Feature effect (FE) \citep{Gromping2020MAEP} is a fundamental category
of global explainability methods. The objective of FE is to the
isolate and visulalize the impact of a single feature on the
output.~\footnote{FE methods also isolate the effect of a pair of
  features to the output. Combinations of more than two features are
  not usual, because they encounter, among others, visualization
  difficulties.} FE methods suffer from aggregation bias because,
often, the rationale behind the average effect might be unclear. For
example, a feature with zero average effect may indicate that the
feature has no effect on the output or, contrarily, it has a highly
positive effect in some cases and a highly negative in others. There
are three widely-used FE methods; Partial Dependence Plots
(PDP)\citep{friedman2001greedy}, Marignal Plots
(MP)\citep{apley2020visualizing} and Aggregated Local Effects
(ALE)\citep{apley2020visualizing}. PDP and MP have been criticized for
computing erroneous effects when the input features are (highly)
correlated, which is a frequent scenario in many ML
problems. Therefore, ALE has been established as the state-of-the-art
FE method.

However, ALE faces two crucial drawbacks. First, it does not provide a
way to inform the user about potential heterogeneous effects that are
hidden behind the average effect. In contrast, in the case of PDP, the
heterogeneous effects can be spotted by exploring the Individual
Conditional Expectations (ICE)\citep{goldstein2015peeking}. Second,
ALE requires an additional step where the axis of the feature of
interest is split in \(K\) fixed-size non-overlapping intervals. So
far, the user is asked to provide a value for the parameter \(K\)
blindly, i.e without an indication about whether a big or a small
value could be more appropriate, which often leads to unstable
explanations. For convenience, in the rest of the paper we will refer
to this step using the term bin-splitting problem.

In this paper, we extend ALE with a probabilistic component for
measuring the uncertainty of the global explanation. The uncertainty
of the global explanation expresses how certain we are that the global
(averaged) explanation is valid if applied to an instance drawn at
random. The probabilistic extension completes ALE, as ICE plots
complement PDP, for revealing the heterogeneous effects. Furthermore,
we transform the bin-splitting step into a data-driven clustering
problem, i.e., we search for the optimal splitting given available
instances of the training set. We, also, present a
computationally-grounded algorithm for finding the optimal
solution.

\paragraph{Contributions.} The contributions of this paper are the following:

\begin{itemize}
\item We introduce NAME, an extension of ALE that quantifies the
  uncertainty of the global explanation, i.e.~the level of
  heterogeneous effects hidden behind the global explanation.
\item We present an algorithm that automatically computes the optimal
  bin-splitting
\item We formally prove that our method finds the optimal grouping of
  samples, minimizing the added uncertainty over the unavoidable
  heterogeneity.
\item We provide empirical evaluation of the method in artificial and
  real datasets.
\end{itemize}

The implementation of our method and the code for reproducing all the
experiments is provided in the submission and will become publicly
available upon acceptance.


\section{BACKGROUND AND RELATED WORK}

\paragraph{Notation.} We refer to random variables (rv) using
uppercase \( X \), whereas to simple variables with plain lowercase
\( x \). Bold denotes a vector; \( \xb \) for simple variables or
\(\mathbf{X}\) for rvs. Often, we partition the input vector
\(\xb \in \mathbb{R}^D\) to the feature of interest
\(x_s \in \mathbb{R} \) and the rest of the features
\(\xc \in \mathbb{R}^{D-1}\). For convenience we denote it as
\((x_s, \mathbf{x}_c)\), but we clarify that it corresponds to the
vector \((x_1, \cdots , x_s, \cdots, x_D)\). Equivalently, we denote
the corresponding rv as \(X = (X_s, \mathbf{X}_c)\). The black-box
function is \(f : \mathbb{R}^D \rightarrow \mathbb{R}\) and the
FE of the \(s\)-th feature is
\(f^{\mathtt{<method>}}(x_s)\), where \(\mathtt{<method>}\) is the
name of the FE method.\footnote{An extensive list of all
  symbols used in the paper is provided in the helping material.}

\paragraph{Feature Effect Methods.} The three well-known feature
effect methods are: PDP, MP and ALE. PDP formulates the FE
of the \(s\)-th attribute as an expectation over the marginal
distribution \(\mathbf{X}_c\), i.e.,
\(f^{\mathtt{PDP}}(x_s) =
\mathbb{E}_{\mathbf{X}_c}[f(x_s,\mathbf{X}_c)]\), whereas MP
formulates it as an expectation over the conditional
\(\mathbf{X}_c|X_s\), i.e.,
\(f^{\mathtt{MP}}(x_s) = \mathbb{E}_{\mathbf{X}_c|X_s = x_s}[f(x_s,
\mathbf{X}_c)]\). ALE computes the global effect at \(x_s\) as the
accumulation of the averaged local effects:

\begin{equation}
  \label{eq:ALE_accumulated_mean}
  f^{\mathtt{ALE}}(x_s) = \int_{z_{s,min}}^{x_s} \mathbb{E}_{\Xcb|X_s=z}\left[\frac{\partial f(z, \Xcb)}{\partial z}\right] \partial z
\end{equation}
%
ALE has specific advantages which gain particular value in cases of
corelated input features. In these cases, PDP integrates over
unrealistic instances, due to the use of the marginal distribution
\(\mathbf{X}_c \), and MP computes aggregated effects, i.e., imputes
the combined effect of sets of features to a single feature. ALE
manages to resolve both issues, and is therefore the only trustable
FE method in cases of correlated features.

\paragraph{Quantify the Heterogeneous Effects.}

FE methods answer the question \textit{what is expected to happen to
  the output (expected effect), if the value of a specific feature is
  increased/decreased}. Having an answer to the question above, it
comes naturally to also wonder \textit{how certain we are about the
  expected change (uncertainty)}. For this reason, the quantification
of the uncertainty along with the expected effect has attracted a lot
of interest. The level of uncertainty is mostly quantified by
measuring the existence of heterogeneous effects, i.e. whether there
are local explanations that deviate from the expected global
effect. ICE and d-ICE plots provide a visual understanding of the
heterogeneous effects on top of PDPs. Another approach targets on
grouping the heterogeneous effects, e.g., allocating ICE plots in
homogeneous clusters, by dividing the input
space.\citep{molnar2020model} Some other approaches, like H-Statistic,
Greenwel, move a step behind and try to quantify the level of
interaction between the input features, a possible cause of
heterogeneous effects. In this case, the interpretation is indirect,
since a strong interaction index is only an indicator of heterogeneous
effects. The aforementioned approaches face two pathogenies; They
either do not quantify the uncertainty of the FE directly or they are
based on PDPs, and, therefore, they are subject to the failure modes
of PDPs in cases of correlated features. To the best of our knowledge,
no method so far targets on quantifying the uncertainty of ALE.

\paragraph{Bin-Splitting for ALE estimation.}

In real ML scenarios, the expected FE and the uncertainty are
estimated from the limited instances of the training set.
\citep{apley2020visualizing} proposed estimating the local effects in
each bin by evaluating the black box-funtion at the bin limits:
\begin{equation}
  \label{eq:ALE_accumulated_mean_est}
  \hat{f}^{\mathtt{ALE}}(x_s) = \sum_{k=1}^{k_x} \frac{1}{|\mathcal{S}_k|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}_k} \left [ f(z_{k}, \xc^i) - f(z_{k-1}, \xc^i)) \right ]
\end{equation}
We denote as \(k_x\) the index of the bin that \(x_s\) belongs to,
i.e. \(k_x: z_{k_x-1} \leq x_s < z_{k_x} \) and \(\mathcal{S}_k\) is
the set of training instance that lie in the \(k\)-th bin, i.e.
\( \mathcal{S}_k = \{ \xb^i : z_{k-1} \leq x^i_s < z_{k} \}
\). Afterwards, (cite) proposed the Differential ALE (DALE) that
exploits differentiaton for computing the local effects on the instances
training-set, instead of the bin limits:
\begin{equation}
  \label{eq:DALE_accumulated_mean_est}
  \hat{f}^{\mathtt{DALE}}(x_s) = \Delta x \sum_{k=1}^{k_x} \frac{1}{|\mathcal{S}_k|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}_k} \frac{\partial f}{\partial x_s}(\mathbf{x}^i)
\end{equation}
%
Their method has the advantages of remaining on-distribution even when
bins become wider and, most importantly, allows the recomputation of
the accumulated effect with different bin-splitting with near-zero
computational cost. However, none of the approximations above deals
with the crucial problem of bin-spliting. As indicated
by~\citep{molnar2022}, in ALE the effects are computed per interval
(region) and the interpretation of the effect can only be
local.


\section{THE NAME METHOD}
\label{sec:NAME-method}

In Section~\ref{sec:NAME-definition} we define the component for the
uncertainty quantification. In
Section~\ref{sec:interval-based-estimation}, we show how to estimate
the average effect and the uncertainty from the limited samples of the
training set and we make an important proof about the aggregated
variance defined over a bin. In Section~\ref{sec:interval-spliting},
we define and solve the problem of optimal bin-splitting. Finally, in
Section~\ref{sec:visualization}, we illustrate the appropriate
visualization of NAME for facilitating its interpretation by a
non-expert and we discuss important aspects of the method

\subsection{Uncertainty Quantification}
\label{sec:NAME-definition}

ALE defines the local effect of the \(s\)-th feature on \(f(\cdot)\)
at point \((x_s, \xc)\) as \(\dfdx (x_s, \xc)\). All the local
explanations at \(x_s\) are, then, weigthed by the conditional
distribution \(p(\xc|x_s)\) and are averaged, to produce the
summarized effect at \(x_s\):

\begin{equation}
  \label{eq:ALE_mean}
  \mu(x_s) = \mathbb{E}_{\Xcb|x_s}\left [\dfdx (x_s, \Xcb)\right ]
\end{equation}
%
The FE at \(x_s\) is the accumulation of the averaged
local effects from \(x_{s, min}\) until \(x_s\), i.e.
\(f^{\mathtt{ALE}}(x_s) = \int_{x_{s, min}}^{x_s} \mu(z) \partial z
\). As described at the Introduction, limiting the explanation to the
exepected value level does not shed light to possible heterogeneous
effects behind the averaged explanation. Therefore, we model the
uncertainty of the local effects at \(\mathcal{H}(x_s)\) as the
variance of the local explanations:

\begin{equation}
  \label{eq:ALE_var}
  \mathcal{H}(x_s) := \sigma^2(x_s) = \mathrm{Var}_{\Xcb|x_s}\left [\dfdx (x_s, \Xcb) \right ]
\end{equation}
\noindent
The uncertainty of the explanation emerges from the natural
characteristics of the experiment, i.e.,~the data generating
distribution and the properties of the black-box function. In
Section~\ref{sec:visualization}, we propose appropriate visualizations
for easier interpretation of Eq.~(\ref{eq:ALE_var}). In ALE, the
FE at \(x_s\) is the accumulation of the averaged local
effects from \(x_{min}\) until \(x_s\), as shown in
Eq.~(\ref{eq:ALE_accumulated_mean}). Equivalently, we define the
accumulated uncertainty (variance) until \(x_s\), as the integral of
the variances of the local effects:

\begin{equation}
  \label{eq:ALE_accumulated_var}
  f^{\mathtt{ALE}}_{\sigma^2}(x_s) = \int_{z_{s, min}}^{x_s} \sigma^2(z) \partial z
\end{equation}
\noindent

The accumulated uncertainty is not a directly interpretable
quantity. It only helps us define a sensible objective for the
interval spliting step, as we discuss in
Section~\ref{sec:interval-spliting}.

\subsection{Interval-Based Estimation}
\label{sec:interval-based-estimation}

In real scenarios, we have ignorance about the data-generating
distribution \(p(x_s, \mathbf{x}_c)\), so, the estimations are based
on the limited instances of the training set. Estimating
Eqs.~\eqref{eq:ALE_mean},~\eqref{eq:ALE_var} at the granularity of a
point is impossible, because the probability of observing a sample
inside the interval \([x_s - h, x_s + h]\) tends to zero, when
\(h \to 0\). We are, therefore, obliged to split the axis of \(x_s\)
into a sequence of non-overlaping intervals (bins) and estimate the
mean and the variance from the samples that lie inside each bin. The
mean effect at an interval \([z_1, z_2)\) is defined as the mean of
the expected effects:

\begin{equation}
  \label{eq:mu_bin}
  \mu(z_1, z_2) = \frac{1}{z_2 - z_1} \int_{z_1}^{z_2}
  \mathbb{E}_{\xc|x_s=z}\left [\frac{\partial f}{\partial x_s} \right ] \partial z
\end{equation}

\noindent
Similarly, the accumulated variance at an interval \([z_1, z_2)\) is
defined as:

\begin{equation}
  \label{eq:var_bin}
  \sigma^2(z_1, z_2) = \int_{z_1}^{z_2}
  \mathbb{E}_{\xc|x_s=z} \left [ (\frac{\partial
      f}{\partial x_s} - \mu(z_1, z_2) )^2 \right] \partial z
\end{equation}
\paragraph{Theorem 1.} If we define the residual \(\rho(z)\) as the
difference between the expected effect at \(x_s\) and the mean
expected effect at the interval, i.e
\(\rho(z) = \mu(z) - \mu(z_1, z_2)\), then, the accumulated variance
at an interval \([z_1, z_2)\) is the accumulation of the all variances
plus the accumulation of squared residuals inside the interval:

\begin{equation}
 \sigma^2(z_1, z_2) = \int_{z_1}^{z_2} \sigma^2(z) + \rho^2(z) \partial z
\end{equation}
%
The proof is in the Appendix. Theorem 1 decouples the accumulated
variance at an interval into two terms. The first term
\(\int_{z_1}^{z_2} \sigma^2(z) \partial z\), quantifies the aggregated
uncertainty due to the natural characteristics of the experiment
\(\mathcal{H}\) and the second term adds extra nuisance uncertainty
due to the limited resolution \(\mathcal{H}_n\). In other words,
enforcing the computation of a single effect for all points in
\([z_1, z_2)]\), burdens the estimation inside the interval with a
nuisance uncertainty of:

\begin{equation}
  \label{eq:uncertainty_bin}
  \mathcal{H}_{bin}(z_1, z_2) = \int_{z_1}^{z_2} \mathcal{H}(z) + \mathcal{H}_n(z) \partial z
\end{equation}


Eqs.~\eqref{eq:mu_bin},~\eqref{eq:var_bin} can be directly estimated
from the set \(\mathcal{S}\) of the dataset instances with the
\(s\)-th feature lying inside the interval, i.e.,
\( \mathcal{S}= \{ \mathbf{x}^i : z_1 \leq x^i_s < z_2 \} \). The mean
effect at the interval, Eq.~(\ref{eq:mu_bin}) is approximated by:

\begin{equation}
  \label{eq:mean_estimation}
  \hat{\mu}(z_1, z_2) = \frac{1}{|\mathcal{S}|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}} \left [ \dfdx(\mathbf{x}^i) \right ]
\end{equation}

and the accumulated variance, Eq.~(\ref{eq:var_bin}) can be
approximated by

\begin{equation}
  \label{eq:variance_estimation}
  \hat{\sigma}^2(z_1, z_2) = \frac{z_2 - z_1}{|\mathcal{S}|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}} \left ( \dfdx(\mathbf{x}^i) - \hat{\mu}(z_1, z_2) \right )^2
\end{equation}


The approximation is unbiased only if the points are uniformly
distributed in \([z_1, z_2]\). Elaborate.

\subsection{Interval Spliting As A Clustering Problem}
\label{sec:interval-spliting}


% Instead, we propose treating the axis-spliting step as an unsupervised
% clustering problem. The objective of the clustering problem should
% fulfill in the best way to contradictory ojectives. First, secure
% robust estimations of the expected effect and the uncertainty inside
% each bin given the limited instances of the training set and, second,
% create bins with as homogeneous local effects as possible, for not
% losing fine-grain resolution FEs due to wide bins.


We formulate the axis-splitting as an unsupervised clustering
problem. We search for the optimal bin splitting, i.e., the number and
size of consecutive non-overlapping intervals that minimizes the
accumulated variance. The optimization problem is defined as follows:

\begin{equation}
  \label{eq:opt}
\begin{aligned}
\min_{ \{z_0, \ldots, z_K\}} \quad & \mathcal{L} = \sum_{k=1}^K \hat{\sigma}^2(z_{k-1}, z_k) \\
\textrm{s.t.} \quad & |\mathcal{S}_k| \geq N\\
\end{aligned}
\end{equation}

The objective of the optimization problem is the sum of the
accumulated variances in each bin, estimated by the instances of the
training set. As we prove in Theorem 1,
\(\mathcal{L} = \sum_{k=1}^K \mathcal{H}_{bin}(z_{k-1}, z_k)\) is the
sum of the uncertainty of the local explanations \(\mathcal{H}\) due
to heterogeneous effects and the added nuisance uncertainty due to
bin-splitting \(\mathcal{H}_n\). Given that \(\mathcal{H}\) is not
affected by interval splitting, optimizing \(\mathcal{L}\) equals to
finding the sequence of non-overlaping bins that add the minimum
nuisance uncertainty. The restriction of (\ref{eq:opt}) secures that
each bin is populated with enough samples for a robust estimation,
which is set by the parameter \(N\). In other words, the user makes
the following proposal; \textit{find the bin sequence that adds the
  minimum nuisance uncertainty, given that I want at least \(N\)
  points per bin}.

\subsubsection{Algorithm For Solving The Clustering Problem}
\label{sec:dynamic-programing}

Solving the problem of finding (a) the optimal number of bins \(K\)
and (b) the optimal bin limits for each bin
\([z_{k-1}, z_k] \forall k\) to minimize:

\begin{equation}
  \label{eq:1}
  \mathcal{L} = \sum_{k=0}^K \hat{\sigma}_k(z_{k-1}, z_k)
\end{equation}
%
The constraints are that all bins must include more than \(\tau\)
points, i.e., \(|\mathcal{S}_k| \geq \tau\).

\noindent

\begin{itemize}
\item Computational complexity
\end{itemize}


% Furthermore, we automate the step of splitting the axis into non-overlapping intervals. The need for non-overlapping bins emerges from the ignorance of the data-generating distribution, enforcing all estimations to be based on the limited instances of the training set. Therefore, there is an implicit trade-off behind the formation of bins. Each bin must include enough instances for a robust estimation of the bin FE (expected value), and the uncertainty of the explanation (variance). On the other hand, each bin should include points with similar local effects. Therefore, we transform the bin splitting step into an unsupervised clustering problem, encoding the trade-off mentioned above in the objective function. We formally show that the objective of the clustering problem has lower-bound the (unavoidable) heterogeneity, i.e., the aggregated uncertainty of the global explanation. Therefore, we aim to find the optimal grouping of samples that adds the slightest uncertainty over the unavoidable heterogeneity. We finally solve the minimization problem by finding the global optimum using dynamic programming. Our method works out of the box without requiring any input by the user. We provide a theoretical and empirical evaluation of our method.


\subsection{Visualization of NAME Method and Discussion}
\label{sec:visualization}

\begin{itemize}
\item Discuss about the meaning of ALE, to find intervals with some effect
\end{itemize}

\section{SYNTHETIC EXAMPLES}

\section{REAL-WORLD EXAMPLES}


\subsubsection*{Acknowledgements}
All acknowledgments go at the end of the paper, including thanks to reviewers who gave useful comments, to colleagues who contributed to the ideas, and to funding agencies and corporate sponsors that provided financial support. 
To preserve the anonymity, please include acknowledgments \emph{only} in the camera-ready papers.

\bibliography{biblio}

\end{document}
