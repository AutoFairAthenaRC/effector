\documentclass[twoside]{article}

\usepackage{aistats2023}
% If your paper is accepted, change the options for the package
% aistats2023 as follows:
%
%\usepackage[accepted]{aistats2023}
%
% This option will print headings for the title of your paper and
% headings for the authors names, plus a copyright note at the end of
% the first column of the first page.

% If you set papersize explicitly, activate the following three lines:
%\special{papersize = 8.5in, 11in}
%\setlength{\pdfpageheight}{11in}
%\setlength{\pdfpagewidth}{8.5in}

% If you use natbib package, activate the following three lines:
\usepackage[round]{natbib}
\renewcommand{\bibname}{References}
\renewcommand{\bibsection}{\subsubsection*{\bibname}}
\bibliographystyle{plainnat}
\usepackage{amsmath}
\usepackage{amssymb}

% If you use BibTeX in apalike style, activate the following line:
%\bibliographystyle{apalike}


\newcommand{\dfdx}{\frac{\partial f}{\partial x_s}}
\newcommand{\xc}{\mathbf{x_c}}
\newcommand{\DY}{\mathbf{\Delta Y}}
\newcommand{\xb}{\mathbf{x}}
\newcommand{\Xcb}{\mathbf{X}_c}
\newcommand{\Xb}{\mathcal{X}}

\begin{document}

% If your paper is accepted and the title of your paper is very long,
% the style will print as headings an error message. Use the following
% command to supply a shorter title of your paper so that it can be
% used as headings.
%
%\runningtitle{I use this title instead because the last one was very long}

% If your paper is accepted and the number of authors is large, the
% style will print as headings an error message. Use the following
% command to supply a shorter version of the authors names so that
% they can be used as headings (for example, use only the surnames)
%
%\runningauthor{Surname 1, Surname 2, Surname 3, ...., Surname n}

\twocolumn[

\aistatstitle{Instructions for Paper Submissions to AISTATS 2023}

\aistatsauthor{ Author 1 \And Author 2 \And  Author 3 }

\aistatsaddress{ Institution 1 \And  Institution 2 \And Institution 3 } ]

\begin{abstract}
  The Abstract paragraph should be indented 0.25 inch (1.5 picas) on
  both left and right-hand margins. Use 10~point type, with a vertical
  spacing of 11~points. The \textbf{Abstract} heading must be centered,
  bold, and in point size 12. Two line spaces precede the
  Abstract. The Abstract must be limited to one paragraph.
\end{abstract}


\section{INTRODUCTION}


Recently, ML has flourished in critical domains, such as healthcare
and finance. In these areas, we need ML models that predict accurately
but also with the ability to explain their predictions. Therefore,
Explainable AI (XAI) is a rapidly growing field due to the interest in
interpreting black box machine learning (ML) models. XAI literature
distinguishes between local and global interpretation
methods~\citep{Molnar2020interpretable}. Local methods explain a
specific prediction, whereas global methods explain the entire model
behavior. Global methods provide a universal explanation, summarizing
the numerous local explanations into a single interpretable outcome
(number or plot). For example, if a user wants to know which features
are significant (feature importance) or whether a particular feature
has a positive or negative effect on the output (feature effect), they
should opt for a global explainability technique. Aggregating the
individual explanations for producing a global one comes at a cost. In
cases where feature interactions are strong, the global explanation
may obfuscate heterogeneous effects~\citep{Herbinger2022repid} that
exist under the hood, a phenomenon called aggregation
bias~\citep{mehrabi2021survey}.

Feature effect forms a fundamental category of global explainability
methods, isolating a single feature's average impact on the
output. Feature effect methods suffer from aggregation bias because
the rationale behind the average effect might be unclear. For example,
a feature with zero average effect may indicate that the feature has
no effect on the output or, contrarily, it has a highly positive
effect in some cases and a highly negative one in others.

There are two widely-used feature effect methods; Partial Dependence
Plots (PDPlots)\citep{friedman2001greedy} and Aggregated Local Effects
(ALE)\citep{apley2020visualizing}. PDPlots have been criticized for
producing erroneous feature effect plots when the input features are
correlated due to marginalizing over out-of-distribution synthetic
instances. Therefore, ALE has been established as the state-of-the-art
feature effect method since it can isolate feature effects in
situations where input features are highly correlated.

However, ALE faces two crucial drawbacks. First, it does not provide a
way to inform the user about potential heterogeneous effects that are
hidden behind the average effect. In contrast, in the case of PDPlots,
the heterogeneous effects can be spotted by exploring the Individual
Conditional Expectations (ICE)\citep{goldstein2015peeking}. Second,
ALE requires an additional step, where the axis of the feature of
interest is split in \(K\) fixed-size non-overlapping intervals, where
\(K\) is a hyperparameter provided by the user. This splitting is done
blindly, which can lead to inconsistent explanations.

In this paper, we extend ALE with a probabilistic component for
measuring the uncertainty of the global explanation. The uncertainty
of the global explanation expresses how certain we are that the global
(expected) explanation is valid if applied to an instance drawn at
random and informs the user about the level of heterogeneous effects
hidden behind the expected explanation. Our method completes ALE, as
ICE plots complement PDPlots, for revealing the heterogeneous effects.

Our method also automates the step of axis splitting into
non-overlapping intervals. We, firstly, transform the bin splitting
step into an unsupervised clustering problem and, second, find the
optimal bin splitting for a robust estimation of (a) the global
(expected) effect and (b) the uncertainty of the explanation from the
limited samples of the training set. We formally prove that the
objective of the clustering problem has as lower-bound the aggregated
uncertainty of the global explanation. Our method works out of the box
without requiring any input from the user.

\paragraph{Contributions.} The contributions of this paper are the following:

\begin{itemize}
\item We introduce Uncertainty DALE (UDALE), an extension of DALE that
  quantifies the uncertainty of the global explanation, i.e.~the level
  of heterogeneous effects hidden behind the global explanation.
\item
  We provide an algorithm that automatically computes the optimal bin
  splitting for robustly estimating the explanatory quantities, i.e.,
  the global effect and the uncertainty.
\item We formally prove that our method finds the optimal grouping of
  samples, minimizing the added uncertainty over the unavoidable
  heterogeneity that is the lower-bound of the objective.
\item We provide empirical evaluation of the method in artificial and
  real datasets.
\end{itemize}


The implementation of our method and the code for reproducing all the
experiments is provided in the submission and will become publicly
available upon acceptance.


\section{BACKGROUND AND RELATED WORK}

\paragraph{Notation.}

We refer to random variables (rv) using uppercase \( X \), whereas to
simple variables with plain lowercase \( x \). Bold denotes a vector;
\( \xb \) for simple variables or \(\mathbf{X}\) for rvs. Often, we
partition the input vector \(\xb \in \mathbb{R}^D\) to the feature of
interest \(x_s \in \mathbb{R} \) and the rest of the features
\(\xc \in \mathbb{R}^{D-1}\). For convenience we denote it as
\((x_s, \mathbf{x}_c)\), but we clarify that it corresponds to the
vector \((x_1, \cdots , x_s, \cdots, x_D)\). Equivalently, we denote
the corresponding rv as \(X = (X_s, \mathbf{X}_c)\). The black-box
function is \(f : \mathbb{R}^D \rightarrow \mathbb{R}\) and the
feature effect of the \(s\)-th feature is
\(f^{\mathtt{<method>}}(x_s)\), where \(\mathtt{<method>}\) is the
name of the feature effect method.\footnote{An extensive list of all
  symbols used in the paper is provided in the helping material.}


\paragraph{Feature Effect Methods.} PDPlots formulate the feature
effect of the \(s\)-th attribute as an expectation over the marginal
distribution \(\mathbf{X}_c\), i.e.,
\(f^{\mathtt{PDP}}(x_s) =
\mathbb{E}_{\mathbf{X}_c}[f(x_s,\mathbf{X}_c)]\). MPlots formulate it
as an expectation over the conditional \(\mathbf{X}_c|X_s\), i.e.,
\(f^{\mathtt{MP}}(x_s) = \mathbb{E}_{\mathbf{X}_c|X_s = x_s}[f(x_s,
\mathbf{X}_c)]\). ALE computes the global effect at \(x_s\) as an
integration of local effects. The local effects are measured as the
expected change on the output
\( \frac{\partial f(x_s, \mathbf{X}_c)}{\partial x_s} \) over the
conditional distribution \( \Xcb|X_s\). The formula that
defines ALE is presented below:

\begin{equation}
  \label{eq:ALE_accumulated_mean}
  f^{\mathtt{ALE}}(x_s) = c + \int_{z_{s,min}}^{x_s} \mathbb{E}_{\Xcb|X_s=z}\left[\frac{\partial f(z, \Xcb)}{\partial z}\right] \partial z
\end{equation}
%
The constant \(c\) is used for centering the ALE plot. PDPlots
integrate over unrealistic instances due to the use of the marginal
distribution \( p(\mathcal{X}_1) \). Therefore, they incorrectly
result in a quadratic effect in the region \(x_1 \in [0, 1]\). MPlots
resolve this issue using the conditional distribution
\( \mathcal{X}_2|\mathcal{X}_1 \) but suffer from computing combined
effects. ALE plots resolve, both they have two drawbacks TODO add more
info.

\paragraph{Qunatify the Heterogeneous Effects.} It is crucial for
feature effect methods to inform about the heterogeneous
effects. Elaborate. Interpretation of the heterogeneous effects behind
the global effect is available only for PDP, with three different
approaches; (a) ICE and d-ICE plots provide a visual understanding of
the heterogeneous effects. (b) grouping of ICE in homogeneous
clusters, for spliting the input space into subspace(s) with
homogeneous effects (c) Feature Interaction strength indexes, like
H-statistic, provide a value indicating how much a feature interacts
with the others (not the type of interaction). There is no method for
quantifying the heterogeneous effects, based on ALE. Therefore, no
method to exploit the advantages of ALE while, on the same time,
informing about the heterogeneous effects.

\paragraph{Bin Spliting.} ALE also has the peculiarity of spliting the
axis into intervals, allocating the instances of the training set in
the intervals and compute a single (constant) effect in each
interval. With DALE extension, bin spliting is decoupled from instant
effect estimation. With our extension for measuring the heterogeneous
effects, we transfrom interval spliting from a step to a clustering
problem with a meaningful objective to minimise. We provide a thorough
analysis, where we show that our objective has a consistent
meaning. It can be split in two parts; the first part is the
unavoidable uncertainty due to the natural characteristics of the
experiment, i.e.,~the data generating distribution and the black-box
function. The second part is an added uncertainty due to the
limited-samples estimation, that enforces to create groups with
constant main effect. We opt for minimizing the objective, i.e. sum of
the two uncertainties, that given that the first uncertainty is
independent of the bin spliting, therefore we want to minimize the
added uncertainty. To conclude, we transform the axis-spliting into an
unsupervised clustering problem with a principled objective. We a
computationally-grounded solution that works out-of-the-box, relaxing
the user from providing a hyperparameter without any indication which
one is the correct. This step can be used independently of whether the
user wants to explore the heterogeneous effects or not.

\section{THE ... METHOD}

The terms \textit{uncertainty of explanation} and \textit{level of
  heterogeneous effects} refer to the same effect 

\subsection{ALE with Uncertainty Quantification}

ALE defines the local effect of \(x_s\) on \(f(\cdot)\) at
\((x_s, \xc)\) as \(\dfdx (x_s, \xc)\). Given that the black-box
function \(f(\cdot)\) is a deterministic predictor, the local effect
is also a deterministic quantity. Global methods summarize the local
explanations into a single quantity. Therefore, ALE summarizes all the
local explanations at \(x_s\) by averaging the local effects across
all values of \(\xc\) weighting them by \(p(\xc|x_s)\). In other
words, ALE globalizes the local explanations at \(x_s\), computing the
expected effect at \(x_s\):

\begin{equation}
  \label{eq:ALE_mean}
  \mu(x_s) = \mathbb{E}_{\Xcb|x_s}\left [\dfdx (x_s, \Xcb)\right ]
\end{equation}
\noindent
As described at the Introduction, limiting the explanation at this
level does not shed light to possible heterogeneous effects behind the
averaged explanation. Therefore, we model the uncertainty of the local
effects at \(x_s\) as the variance of the local explanations:

\begin{equation}
  \label{eq:ALE_var}
  \sigma^2(x_s) = \mathrm{Var}_{\Xcb|x_s}\left [\dfdx (x_s, \Xcb) \right ]
\end{equation}
\noindent
The uncertainty of the explanation emerges from the natural
characteristics of the experiment, i.e.,~the data generating
distribution and the black-box function. It is important to clarify
that the variance is only a way to model the uncertainty. Other
statistical properties can also be used. Elaborate.

ALE computes the final effect at \(x_s\) by accumulating/integrating
the averaged local effects \(\mu (x_s=z) \) over all values of \(z\)
from \(x_{min}\) until \(x_s\), as show in Eq.~(\ref{eq:ALE_accumulated_mean}). The
choice for \(x_{min}\) is not important, as it only affects the
centering of ALE plot along the vertical axis. Equivalently, we define
the accumulated uncertainty (variance) until the point \(x_s\), as the
integral of the variance of local effects:

\begin{equation}
  \label{eq:ALE_accumulated_var}
  f^{\mathtt{ALE}}_{\sigma^2}(x_s) = \int_{z_{s, min}}^{x_s} \sigma^2(z) \partial z
\end{equation}
\noindent
In ALE plots the accumulated effect as absolute value is not an
interpretable quantity and is only used for better visual
interpretation\citep{Gromping2020MAEP}. The meaningful interpretation
is the effect at a specific point, i.e., what happens to the output
given a small change in the feature of interest. The integration takes
place only for making the visual interpretation easier, for example,
to spot larger intervals where the effect of a \textbf{local} change
is continuously constant. The same stands for the accumulated
uncertainty. The uncertainty has a meaninful interpretation as the
level of heterogeneous effects, only at a specific point. In the
experimental Section, we propose appropriate visualizations to
communicate to this effect to the user. However, the accumulated
uncertainty, i.e., the aggregated variance of the local effects, helps
us define a sensible objective for the interval spliting step. (TODO:
check here if the idea about whether the accumulated uncertainty is a
good metric for modeling the interaction strength)

\subsection{Uncertainty Quantification and Estimation at an Interval}

In real scenarios, we have ignorance about the data-generating
distribution \(p(x_s, \mathbf{x}_c)\) and all estimations are based on
the limited instances of the training set. Unfortunately, it is
impossible to estimate Eqs.~\eqref{eq:ALE_mean},~\eqref{eq:ALE_var} at
the granularity of a point \(x_s\), because The possibility to observe
a sample in the interval \([x_s - h, x_s + h]\) is zero, when
\(h \to 0\). Therefore, we are obliged split the axis \(x_s\) into a
sequence of larger non-overlaping intervals and estimate mean and
variance at the interval resolution. The mean effect at an interval
\([z_1, z_2)\) is the mean of the expected effects:

\begin{equation}
  \label{eq:mu_bin}
  \mu(z_1, z_2) = \frac{1}{z_2 - z_1} \int_{z_1}^{z_2}
  \mathbb{E}_{\xc|x_s=z}\left [\frac{\partial f}{\partial x_s} \right ] \partial z
\end{equation}

\noindent
Accordingly, the accumulated variance at an interval \([z_1, z_2)\)
is:

\begin{equation}
  \label{eq:var_bin}
  \sigma^2(z_1, z_2) = \int_{z_1}^{z_2}
  \mathbb{E}_{\xc|x_s=z} \left [ (\frac{\partial
      f}{\partial x_s} - \mu(z_1, z_2) )^2 \right] \partial z
\end{equation}

As stated before, Eqs.~\eqref{eq:mu_bin},~\eqref{eq:var_bin} can be
estimated from the set \(\mathcal{S}\) of the instances of the
training set with the \(s\)-th feature lying inside the interval,
i.e., \( \mathcal{S}= \{ \mathbf{x}^i : z_1 \leq x^i_s < z_2 \}
\). The mean effect at the interval, Eq.~(\ref{eq:mu_bin}), can be
approximated by:

\begin{equation}
  \label{eq:mean_estimation}
  \hat{\mu}(z_1, z_2) = \frac{1}{|\mathcal{S}|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}} \left [ \dfdx(\mathbf{x}^i) \right ]
\end{equation}

and the accumulated variance at the interval, Eq.~(\ref{eq:var_bin})
can be approximated by

\begin{equation}
  \label{eq:variance_estimation}
  \hat{\sigma}(z_1, z_2) = \frac{z_2 - z_1}{|\mathcal{S}|} \sum_{i:\mathbf{x}^i \in
    \mathcal{S}} \left ( \dfdx(\mathbf{x}^i) - \hat{\mu}_k(z_1, z_2) \right )^2
\end{equation}

The approximation is unbiased only if the points are uniformly
distributed in \([z_1, z_2]\). (TODOs: Check what happens
otherwise).

\subsection{Bin Spliting as a Clustering Problem}

ALE authors\citep{apley2020visualizing} proposed an approximation of
(\ref{eq:ALE_accumulated_mean}) by partitioning the axis of the
feature of interest into a sequence of non-overlaping bin and
computing a single effect in each bin. Later, (TODO: add citation to
us), proposed the DALE (Differential ALE) approximation that decouples
the two steps. The local effects are computed once using the partial
derivatives on the available instances of the training set,
i.e. \(\frac{\partial f}{\partial x_s}\), and the bin-spliting step,
simply allocates the precomputed local effects into bins, for
estimating the expected effect in each bin. The formula that estimates
the accumulate effects is:

\begin{equation}
  f^{\mathtt{DALE}}(x_s) = \Delta x \sum_{k=1}^{k_x}
  \frac{1}{|\mathcal{S}_k|} \sum_{i:\xb^i \in \mathcal{S}_k}
  [f_s(\xb^i)] = \Delta x \sum_{k=1}^{k_x} \hat{\mu}_k
 \label{eq:DALE}
\end{equation}

We denote as \(k_x\) the index of the bin that \(x_s\) belongs to,
i.e. \(k_x: z_{k_x-1} \leq x_s < z_{k_x} \) and \(\mathcal{S}_k\) is
the set of training instance that lie in the \(k\)-th bin, i.e.
\( \mathcal{S}_k = \{ \xb^i : z_{k-1} \leq x^i_s < z_{k} \} \). Both
methods face the limitation that the partitioning into non-overlaping
intervals is done blindly. The user pass the total number of bins
\(K\) as a hyperparameter, the bins are defined with equal-size
spliting, and the training instances are allocated accordingly. This
approach is vulnerable to non-robust estimations. The mean effect is
often poorly approximated from a very small number of samples and the
mean effect of empty bins is interpolated from their
neighboors. Furthermore, in our case, we need sufficient sample
populations for estimating the variance of the approximation, apart
from the mean effect.

\subsubsection{Methodology}

For overcoming this limitations, we reformulate the partitioning as a
clustering of the training instances into a sequence variable-size
intervals. The objective of the clustering problem is inspired 


ALE requires splittingthe estimation of the 

In this section, we introduce a framework 

\paragraph{Theorem 1.} If we define the residual \(\rho(z)\) as the
difference between the expected effect at \(x_s\) and the mean
expected effect at the interval, i.e
\(\rho(z) = \mu(z) - \mu(z_1, z_2)\), then, the accumulated variance
at an interval \([z_1, z_2)\) is the accumulation of the all variances
plus the accumulation of squared residuals inside the interval:

\begin{equation}
 \sigma^2(z_1, z_2) = \int_{z_1}^{z_2} \sigma^2(z) + \rho^2(z) \partial z
\end{equation}
%
The proof is at the Appendix. Theorem 1 decouples the accumulated
variance at an interval, the only quantity we can estimate, into two
terms. The first term \(\int_{z_1}^{z_2} \sigma^2(z) \partial z\),
quantifies the uncertainty due to the natural characteristics of the
experiment and the second term adds extra uncertainty due to the
limited resolution.



\paragraph{Uncertainty of the global effect.}

Eq.~\eqref{eq:variance_estimation} gives an approximation of the
uncertainty of the bin effect.
The uncertainty of the global effect is
simply the sum of the uncertainties in the bin effects.

\paragraph{Minimizing the uncertainty}

Solving the problem of finding (a) the optimal number of bins \(K\) and (b) the optimal bin limits for each bin \([z_{k-1}, z_k] \forall k\) to minimize:

\begin{equation}
  \label{eq:1}
  \mathcal{L} = \sum_{k=0}^K \hat{\sigma}_k(z_{k-1}, z_k)
\end{equation}
%
The constraints are that all bins must include more than \(\tau\)
points, i.e., \(|\mathcal{S}_k| \geq \tau\).

\noindent
TODOS. Show theoretically that \(\mathcal{L} \geq \int_{x_{s, \min}}^{x_{s, \max}}\sigma^2(x_s) \partial x_s\)


% Furthermore, we automate the step of splitting the axis into non-overlapping intervals. The need for non-overlapping bins emerges from the ignorance of the data-generating distribution, enforcing all estimations to be based on the limited instances of the training set. Therefore, there is an implicit trade-off behind the formation of bins. Each bin must include enough instances for a robust estimation of the bin feature effect (expected value), and the uncertainty of the explanation (variance). On the other hand, each bin should include points with similar local effects. Therefore, we transform the bin splitting step into an unsupervised clustering problem, encoding the trade-off mentioned above in the objective function. We formally show that the objective of the clustering problem has lower-bound the (unavoidable) heterogeneity, i.e., the aggregated uncertainty of the global explanation. Therefore, we aim to find the optimal grouping of samples that adds the slightest uncertainty over the unavoidable heterogeneity. We finally solve the minimization problem by finding the global optimum using dynamic programming. Our method works out of the box without requiring any input by the user. We provide a theoretical and empirical evaluation of our method.


\subsection{Visualization of ALE with Uncertainty}

\section{SYNTHETIC EXAMPLES}

\section{REAL-WORLD EXAMPLES}


\subsubsection*{Acknowledgements}
All acknowledgments go at the end of the paper, including thanks to reviewers who gave useful comments, to colleagues who contributed to the ideas, and to funding agencies and corporate sponsors that provided financial support. 
To preserve the anonymity, please include acknowledgments \emph{only} in the camera-ready papers.

\bibliography{biblio}


\section*{Appendix}

\subsection{Proof for variance of the bin}



\end{document}
